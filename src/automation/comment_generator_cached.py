import anthropic
import random
import json
import os
import hashlib
import time
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Tuple
from collections import defaultdict


class CachedCommentGenerator:
    """í† í° ì‚¬ìš©ëŸ‰ ìµœì†Œí™”ë¥¼ ìœ„í•œ ìºì‹±ì´ ì ìš©ëœ ëŒ“ê¸€ ìƒì„±ê¸°"""

    def __init__(self, api_key: str):
        self.client = anthropic.Anthropic(api_key=api_key)

        # ìºì‹œ ì„¤ì •
        self.cache_dir = "cache"
        os.makedirs(self.cache_dir, exist_ok=True)

        # ìºì‹œ íŒŒì¼ë“¤
        self.template_cache_file = os.path.join(
            self.cache_dir, "comment_templates.json"
        )
        self.response_cache_file = os.path.join(self.cache_dir, "response_cache.json")
        self.category_cache_file = os.path.join(
            self.cache_dir, "category_patterns.json"
        )

        # ìºì‹œ ë¡œë“œ
        self.template_cache = self.load_cache(self.template_cache_file)
        self.response_cache = self.load_cache(self.response_cache_file)
        self.category_patterns = self.load_cache(self.category_cache_file)

        # í†µê³„
        self.stats = {"api_calls": 0, "cache_hits": 0, "tokens_saved": 0}

        # ì¹´í…Œê³ ë¦¬ë³„ ê¸°ë³¸ í…œí”Œë¦¿
        self.initialize_templates()

    def load_cache(self, file_path: str) -> Dict:
        """ìºì‹œ íŒŒì¼ ë¡œë“œ"""
        if os.path.exists(file_path):
            with open(file_path, "r", encoding="utf-8") as f:
                return json.load(f)
        return {}

    def save_cache(self, data: Dict, file_path: str):
        """ìºì‹œ íŒŒì¼ ì €ì¥"""
        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    def initialize_templates(self):
        """ì¹´í…Œê³ ë¦¬ë³„ ê¸°ë³¸ ëŒ“ê¸€ í…œí”Œë¦¿ ì´ˆê¸°í™”"""
        if not self.template_cache:
            self.template_cache = {
                "ìš”ë¦¬/ë ˆì‹œí”¼": [
                    "ë ˆì‹œí”¼ ë”°ë¼ì„œ ë§Œë“¤ì–´ë´ì•¼ê² ì–´ìš”! {detail} ì •ë§ ë§›ìˆì–´ ë³´ì´ë„¤ìš” ğŸ˜Š",
                    "ìš°ì™€ {detail} ê¿€íŒì´ë„¤ìš”! ì €ë„ ì´ë²ˆ ì£¼ë§ì— ë„ì „í•´ë³¼ê²Œìš”~",
                    "{detail} ë¶€ë¶„ì´ íŠ¹íˆ ì¸ìƒì ì´ì—ìš”. ìì„¸í•œ ë ˆì‹œí”¼ ê³µìœ  ê°ì‚¬í•©ë‹ˆë‹¤!",
                ],
                "ì—¬í–‰": [
                    "{detail} ì •ë§ ë©‹ì§„ ê³³ì´ë„¤ìš”! ì €ë„ ë‹¤ìŒì— ê¼­ ê°€ë³´ê³  ì‹¶ì–´ìš”.",
                    "ì‚¬ì§„ë§Œ ë´ë„ íë§ë˜ëŠ” ëŠë‚Œì´ì—ìš”. {detail} ì¶”ì²œ ê°ì‚¬í•©ë‹ˆë‹¤!",
                    "{detail} ì •ë³´ ë„ˆë¬´ ìœ ìš©í•´ìš”! ì—¬í–‰ ê³„íš ì„¸ìš¸ ë•Œ ì°¸ê³ í• ê²Œìš”~",
                ],
                "ì¼ìƒ/ì—ì„¸ì´": [
                    "{detail} ë¶€ë¶„ì—ì„œ ë§ì€ ê³µê°ì´ ë˜ë„¤ìš”. ì¢‹ì€ ê¸€ ê°ì‚¬í•©ë‹ˆë‹¤.",
                    "ê¸€ ì½ìœ¼ë©´ì„œ {detail} ìƒê°ì´ ë“¤ì—ˆì–´ìš”. ë”°ëœ»í•œ ê¸€ì´ë„¤ìš” :)",
                    "{detail} ì €ë„ ë¹„ìŠ·í•œ ê²½í—˜ì´ ìˆì–´ì„œ ë” ì™€ë‹¿ë„¤ìš”!",
                ],
                "IT/ê¸°ìˆ ": [
                    "{detail} ì„¤ëª…ì´ ì •ë§ ì´í•´í•˜ê¸° ì‰½ê²Œ ë˜ì–´ìˆë„¤ìš”! ì¢‹ì€ ì •ë³´ ê°ì‚¬í•©ë‹ˆë‹¤.",
                    "ì˜¤ {detail} ì´ëŸ° ë°©ë²•ë„ ìˆì—ˆêµ°ìš”! ë°”ë¡œ ì ìš©í•´ë´ì•¼ê² ì–´ìš”.",
                    "{detail} íŒ ë„ˆë¬´ ìœ ìš©í•´ìš”! ê°œë°œí•˜ë©´ì„œ ë§‰í˜”ë˜ ë¶€ë¶„ì¸ë° ë„ì›€ì´ ëì–´ìš”.",
                ],
                "ë·°í‹°/íŒ¨ì…˜": [
                    "{detail} íŒ ë„ˆë¬´ ì¢‹ì•„ìš”! ì €ë„ í•œë²ˆ ë”°ë¼í•´ë´ì•¼ê² ë„¤ìš”~",
                    "ì™€ {detail} ì •ë³´ ì°¾ê³  ìˆì—ˆëŠ”ë°! ìì„¸í•œ ë¦¬ë·° ê°ì‚¬í•´ìš” ğŸ’•",
                    "{detail} ì €ë„ ê¶ê¸ˆí–ˆë˜ ë¶€ë¶„ì´ì—ìš”! ë„ì›€ ë§ì´ ëì–´ìš”~",
                ],
            }
            self.save_cache(self.template_cache, self.template_cache_file)

    def get_content_hash(self, title: str, content: str) -> str:
        """ì½˜í…ì¸  í•´ì‹œ ìƒì„± (ìºì‹œ í‚¤ë¡œ ì‚¬ìš©)"""
        # ì œëª©ê³¼ ë‚´ìš©ì˜ ì£¼ìš” ë¶€ë¶„ë§Œ í•´ì‹œ
        key_content = f"{title[:50]}{content[:200]}"
        return hashlib.md5(key_content.encode()).hexdigest()

    def categorize_post(self, title: str, content: str) -> str:
        """í¬ìŠ¤íŠ¸ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        text = f"{title} {content}".lower()

        # ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ
        categories = {
            "ìš”ë¦¬/ë ˆì‹œí”¼": ["ìš”ë¦¬", "ë ˆì‹œí”¼", "ë§›ìˆ", "ì¬ë£Œ", "ì¡°ë¦¬", "ìŒì‹", "ë§Œë“¤ê¸°"],
            "ì—¬í–‰": ["ì—¬í–‰", "ê´€ê´‘", "í˜¸í…”", "ë¹„í–‰ê¸°", "í•´ì™¸", "êµ­ë‚´", "ê´€ê´‘ì§€"],
            "IT/ê¸°ìˆ ": ["í”„ë¡œê·¸ë˜ë°", "ì½”ë”©", "ê°œë°œ", "it", "ì»´í“¨í„°", "ì•±", "ì›¹"],
            "ë·°í‹°/íŒ¨ì…˜": ["í™”ì¥í’ˆ", "íŒ¨ì…˜", "ì˜·", "ì½”ë””", "ë©”ì´í¬ì—…", "ìŠ¤í‚¨ì¼€ì–´"],
            "ì¼ìƒ/ì—ì„¸ì´": ["ì¼ìƒ", "í•˜ë£¨", "ìƒê°", "ëŠë‚Œ", "ì˜¤ëŠ˜", "ì¼ê¸°"],
        }

        # ì¹´í…Œê³ ë¦¬ ì ìˆ˜ ê³„ì‚°
        scores = defaultdict(int)
        for category, keywords in categories.items():
            for keyword in keywords:
                if keyword in text:
                    scores[category] += 1

        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì¹´í…Œê³ ë¦¬ ë°˜í™˜
        if scores:
            return max(scores, key=scores.get)
        return "ì¼ìƒ/ì—ì„¸ì´"  # ê¸°ë³¸ê°’

    def extract_key_detail(self, content: str, category: str) -> str:
        """í¬ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ ë””í…Œì¼ ì¶”ì¶œ"""
        # ì¹´í…Œê³ ë¦¬ë³„ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ ë¡œì§
        sentences = content.split(".")

        if category == "ìš”ë¦¬/ë ˆì‹œí”¼":
            # ì¬ë£Œë‚˜ ì¡°ë¦¬ë²• ê´€ë ¨ ë¬¸ì¥ ì°¾ê¸°
            for sent in sentences:
                if any(word in sent for word in ["ì¬ë£Œ", "ë„£ê³ ", "ë³¶", "ë“"]):
                    return sent.strip()[:30]

        elif category == "ì—¬í–‰":
            # ì¥ì†Œë‚˜ ì¶”ì²œ ê´€ë ¨ ë¬¸ì¥ ì°¾ê¸°
            for sent in sentences:
                if any(word in sent for word in ["ê³³", "ì¶”ì²œ", "ê°€ë³¼ë§Œí•œ", "ëª…ì†Œ"]):
                    return sent.strip()[:30]

        # ê¸°ë³¸: ì²« ë²ˆì§¸ ì˜ë¯¸ìˆëŠ” ë¬¸ì¥
        for sent in sentences:
            if len(sent.strip()) > 10:
                return sent.strip()[:30]

        return "ì´ ë‚´ìš©"

    def check_cache(self, content_hash: str) -> Optional[str]:
        """ìºì‹œì—ì„œ ëŒ“ê¸€ í™•ì¸"""
        if content_hash in self.response_cache:
            cache_entry = self.response_cache[content_hash]

            # ìºì‹œ ë§Œë£Œ í™•ì¸ (7ì¼)
            cached_time = datetime.fromisoformat(cache_entry["timestamp"])
            if datetime.now() - cached_time < timedelta(days=7):
                # ìºì‹œëœ ëŒ“ê¸€ ì¤‘ ëœë¤ ì„ íƒ
                comments = cache_entry["comments"]
                if comments:
                    self.stats["cache_hits"] += 1
                    self.stats["tokens_saved"] += 150  # í‰ê·  í† í° ì ˆì•½ëŸ‰
                    return random.choice(comments)

        return None

    def generate_from_template(self, category: str, detail: str) -> str:
        """í…œí”Œë¦¿ ê¸°ë°˜ ëŒ“ê¸€ ìƒì„±"""
        if category in self.template_cache:
            template = random.choice(self.template_cache[category])
            return template.format(detail=detail)
        return None

    def generate_comment(
        self, post_title: str, post_content: str, post_url: str = None
    ) -> Optional[str]:
        """
        ìºì‹±ì´ ì ìš©ëœ ëŒ“ê¸€ ìƒì„±

        1. ì½˜í…ì¸  í•´ì‹œë¡œ ìºì‹œ í™•ì¸
        2. ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ í›„ í…œí”Œë¦¿ í™•ì¸
        3. í•„ìš”ì‹œì—ë§Œ API í˜¸ì¶œ
        """
        try:
            # 1. ì½˜í…ì¸  í•´ì‹œ ìƒì„±
            content_hash = self.get_content_hash(post_title, post_content)

            # 2. ìºì‹œ í™•ì¸
            cached_comment = self.check_cache(content_hash)
            if cached_comment:
                print(f"ìºì‹œ íˆíŠ¸! í† í° ì ˆì•½: ~150")
                return cached_comment

            # 3. ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
            category = self.categorize_post(post_title, post_content)

            # 4. í•µì‹¬ ë””í…Œì¼ ì¶”ì¶œ
            detail = self.extract_key_detail(post_content, category)

            # 5. í…œí”Œë¦¿ ê¸°ë°˜ ìƒì„± ì‹œë„ (30% í™•ë¥ )
            if random.random() < 0.3:
                template_comment = self.generate_from_template(category, detail)
                if template_comment:
                    print(f"í…œí”Œë¦¿ ì‚¬ìš©! í† í° ì ˆì•½: ~200")
                    self.save_to_cache(content_hash, [template_comment])
                    return template_comment

            # 6. API í˜¸ì¶œ (í•„ìš”í•œ ê²½ìš°ë§Œ)
            print("API í˜¸ì¶œ ì¤‘...")
            self.stats["api_calls"] += 1

            # ì½˜í…ì¸  ìš”ì•½ (í† í° ì ˆì•½)
            content_summary = self.summarize_content(post_content, 500)

            prompt = f"""
            ì¹´í…Œê³ ë¦¬: {category}
            ì œëª©: {post_title}
            í•µì‹¬ ë‚´ìš©: {content_summary}
            
            ìœ„ ë¸”ë¡œê·¸ì— ëŒ€í•œ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ“ê¸€ 3ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
            ê° ëŒ“ê¸€ì€ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ë¡œ, 1-2ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ê³ , ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•´ì£¼ì„¸ìš”.
            
            ê·œì¹™:
            - êµ¬ì²´ì ì¸ ë‚´ìš© ì–¸ê¸‰
            - ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´
            - ì´ëª¨í‹°ì½˜ ìµœëŒ€ 1ê°œ
            - ê°ê° ë‹¤ë¥¸ ê´€ì 
            """

            response = self.client.messages.create(
                model="claude-3-haiku-20240307",  # ë” ì €ë ´í•œ ëª¨ë¸ ì‚¬ìš©
                max_tokens=200,
                temperature=0.8,
                messages=[{"role": "user", "content": prompt}],
            )

            # ì—¬ëŸ¬ ëŒ“ê¸€ ìƒì„± ë° ìºì‹±
            comments = response.content[0].text.strip().split("\n")
            comments = [c.strip() for c in comments if c.strip()]

            if comments:
                self.save_to_cache(content_hash, comments)
                return random.choice(comments)

            return None

        except Exception as e:
            print(f"ëŒ“ê¸€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return None

    def summarize_content(self, content: str, max_length: int) -> str:
        """ì½˜í…ì¸  ìš”ì•½ (í† í° ì ˆì•½)"""
        if len(content) <= max_length:
            return content

        # ì¤‘ìš” ë¬¸ì¥ ì¶”ì¶œ
        sentences = content.split(".")
        important_sentences = []

        # ìˆ«ì, í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì¥ ìš°ì„ 
        for sent in sentences:
            if any(char.isdigit() for char in sent) or len(sent.strip()) > 20:
                important_sentences.append(sent.strip())

        # ê¸¸ì´ ì œí•œì— ë§ì¶° ë°˜í™˜
        result = ""
        for sent in important_sentences:
            if len(result) + len(sent) < max_length:
                result += sent + ". "
            else:
                break

        return result or content[:max_length]

    def save_to_cache(self, content_hash: str, comments: List[str]):
        """ìºì‹œì— ì €ì¥"""
        self.response_cache[content_hash] = {
            "comments": comments,
            "timestamp": datetime.now().isoformat(),
        }
        self.save_cache(self.response_cache, self.response_cache_file)

    def get_stats(self) -> Dict:
        """í†µê³„ ë°˜í™˜"""
        total_calls = self.stats["api_calls"] + self.stats["cache_hits"]
        cache_rate = (
            (self.stats["cache_hits"] / total_calls * 100) if total_calls > 0 else 0
        )

        return {
            "total_requests": total_calls,
            "api_calls": self.stats["api_calls"],
            "cache_hits": self.stats["cache_hits"],
            "cache_hit_rate": f"{cache_rate:.1f}%",
            "estimated_tokens_saved": self.stats["tokens_saved"],
            "estimated_cost_saved": f"${self.stats['tokens_saved'] * 0.00002:.2f}",  # Haiku ê°€ê²© ê¸°ì¤€
        }

    def cleanup_old_cache(self, days: int = 7):
        """ì˜¤ë˜ëœ ìºì‹œ ì •ë¦¬"""
        current_time = datetime.now()
        cleaned = 0

        # response_cache ì •ë¦¬
        for key in list(self.response_cache.keys()):
            cached_time = datetime.fromisoformat(self.response_cache[key]["timestamp"])
            if current_time - cached_time > timedelta(days=days):
                del self.response_cache[key]
                cleaned += 1

        if cleaned > 0:
            self.save_cache(self.response_cache, self.response_cache_file)
            print(f"ì˜¤ë˜ëœ ìºì‹œ {cleaned}ê°œ ì •ë¦¬ë¨")
